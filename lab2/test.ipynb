{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLmkGxXT1x_X"
      },
      "outputs": [],
      "source": [
        "pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "# Load data from the SQLite database\n",
        "def load_data_from_database():\n",
        "    conn = sqlite3.connect('books.db')\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # Fetch book data including authors, titles, and genres\n",
        "    cursor.execute(\"SELECT authors, title, genres FROM books\")\n",
        "    data = cursor.fetchall()\n",
        "\n",
        "    conn.close()\n",
        "    return data\n",
        "\n",
        "# Preprocess data and create feature representations\n",
        "def preprocess_data(data):\n",
        "    # Separate data into authors, titles, and genres\n",
        "    authors, titles, genres = zip(*data)\n",
        "\n",
        "    # Use MultiLabelBinarizer to one-hot encode genres\n",
        "    mlb = MultiLabelBinarizer()\n",
        "    genre_features = mlb.fit_transform(genres)\n",
        "\n",
        "    # Create embeddings for authors and titles (example: word embeddings)\n",
        "    # You can use Word2Vec, FastText, or other embedding techniques\n",
        "    # For simplicity, here we use random embeddings\n",
        "    num_authors = len(set(authors))\n",
        "    num_titles = len(set(titles))\n",
        "\n",
        "    author_embeddings = np.random.rand(num_authors, 50)  # 50-dimensional embeddings\n",
        "    title_embeddings = np.random.rand(num_titles, 50)  # 50-dimensional embeddings\n",
        "\n",
        "    return genre_features, author_embeddings, title_embeddings\n",
        "\n",
        "# Define a neural network model for recommendation\n",
        "def create_recommendation_model(num_genres, num_authors, num_titles):\n",
        "    # Example model architecture\n",
        "    genre_input = keras.layers.Input(shape=(num_genres,))\n",
        "    author_input = keras.layers.Input(shape=(50,))\n",
        "    title_input = keras.layers.Input(shape=(50,))\n",
        "\n",
        "    # Define layers and connections\n",
        "    # Customize this architecture based on your requirements\n",
        "    # Concatenate inputs or use other techniques\n",
        "    combined_features = keras.layers.Concatenate()([genre_input, author_input, title_input])\n",
        "    hidden_layer = keras.layers.Dense(128, activation='relu')(combined_features)\n",
        "    output_layer = keras.layers.Dense(num_titles, activation='softmax')(hidden_layer)\n",
        "\n",
        "    model = keras.models.Model(inputs=[genre_input, author_input, title_input], outputs=output_layer)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Train the recommendation model\n",
        "def train_recommendation_model(model, genre_features, author_embeddings, title_embeddings):\n",
        "    # Load user preferences and book ratings from your dataset\n",
        "    # User preferences could be a combination of selected books, ratings, etc.\n",
        "\n",
        "    # Prepare training data (X) and target labels (y)\n",
        "    X = [genre_features, author_embeddings, title_embeddings]\n",
        "    y = user_preferences  # User-specific target labels, e.g., book ratings\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X, y, epochs=10, batch_size=32, validation_split=0.2)  # Adjust parameters as needed\n",
        "\n",
        "# Generate book recommendations using the trained model\n",
        "def generate_recommendations(model, user_preferences, genre_features, author_embeddings, title_embeddings):\n",
        "    # Prepare user-specific input\n",
        "    user_input = [genre_features, author_embeddings, title_embeddings]\n",
        "\n",
        "    # Predict book recommendations\n",
        "    recommendations = model.predict(user_input)\n",
        "\n",
        "    # Sort and select top recommendations\n",
        "    top_recommendations_indices = recommendations.argsort()[-5:][::-1]  # Adjust the number of recommendations as needed\n",
        "    top_recommendations = [book_titles[i] for i in top_recommendations_indices]\n",
        "\n",
        "    return top_recommendations\n",
        "\n",
        "# Main program\n",
        "if __name__ == \"__main__\":\n",
        "    # Load and preprocess data\n",
        "    data = load_data_from_database()\n",
        "    genre_features, author_embeddings, title_embeddings = preprocess_data(data)\n",
        "\n",
        "    # Create and train the recommendation model\n",
        "    num_genres = genre_features.shape[1]\n",
        "    num_authors = author_embeddings.shape[0]\n",
        "    num_titles = title_embeddings.shape[0]\n",
        "\n",
        "    model = create_recommendation_model(num_genres, num_authors, num_titles)\n",
        "    train_recommendation_model(model, genre_features, author_embeddings, title_embeddings)\n",
        "\n",
        "    # Example: Generate book recommendations based on user preferences\n",
        "    user_preferences = [user_genre_features, user_author_embedding, user_title_embedding]\n",
        "    recommendations = generate_recommendations(model, user_preferences, genre_features, author_embeddings, title_embeddings)\n",
        "\n",
        "    print(\"Top Book Recommendations:\")\n",
        "    for i, book in enumerate(recommendations):\n",
        "        print(f\"{i+1}. {book}\")\n"
      ],
      "metadata": {
        "id": "_FXKweP51zRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load data from the SQLite database\n",
        "def load_data_from_database():\n",
        "    conn = sqlite3.connect('books.db')\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # Fetch book data including authors, titles, and genres\n",
        "    cursor.execute(\"SELECT authors, title, genres FROM books\")\n",
        "    data = cursor.fetchall()\n",
        "\n",
        "    conn.close()\n",
        "    return data\n",
        "\n",
        "# Preprocess data and create feature representations\n",
        "def preprocess_data(data):\n",
        "    # Separate data into authors, titles, and genres\n",
        "    authors, titles, genres = zip(*data)\n",
        "\n",
        "    # Use MultiLabelBinarizer to one-hot encode genres\n",
        "    mlb = MultiLabelBinarizer()\n",
        "    genre_features = mlb.fit_transform(genres)\n",
        "\n",
        "    # Use LabelEncoder to encode authors as numerical values\n",
        "    author_encoder = LabelEncoder()\n",
        "    author_ids = author_encoder.fit_transform(authors)\n",
        "\n",
        "    # Create embeddings for titles (example: word embeddings)\n",
        "    # You can use Word2Vec, FastText, or other embedding techniques\n",
        "    # For simplicity, here we use random embeddings\n",
        "    num_titles = len(set(titles))\n",
        "    title_embeddings = np.random.rand(num_titles, 50)  # 50-dimensional embeddings\n",
        "\n",
        "    return genre_features, author_ids, title_embeddings\n",
        "\n",
        "# Define a neural network model for recommendation\n",
        "def create_recommendation_model(num_genres, num_authors, num_titles):\n",
        "    # Example model architecture\n",
        "    genre_input = keras.layers.Input(shape=(num_genres,))\n",
        "    author_input = keras.layers.Input(shape=(1,))\n",
        "    title_input = keras.layers.Input(shape=(50,))\n",
        "\n",
        "    # Define layers and connections\n",
        "    # Customize this architecture based on your requirements\n",
        "    combined_features = keras.layers.Concatenate()([genre_input, author_input, title_input])\n",
        "    hidden_layer = keras.layers.Dense(128, activation='relu')(combined_features)\n",
        "    output_layer = keras.layers.Dense(num_titles, activation='softmax')(hidden_layer)\n",
        "\n",
        "    model = keras.models.Model(inputs=[genre_input, author_input, title_input], outputs=output_layer)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Train the recommendation model\n",
        "def train_recommendation_model(model, genre_features, author_ids, title_embeddings):\n",
        "    # Prepare training data (X) and target labels (y)\n",
        "    X = [genre_features, author_ids, title_embeddings]\n",
        "    y = genre_features  # Use genre_features as target labels (autoencoder)\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X, y, epochs=10, batch_size=32, validation_split=0.2)  # Adjust parameters as needed\n",
        "\n",
        "# Generate book recommendations using the trained model\n",
        "def generate_recommendations(model, user_genres, user_authors, genre_features, author_ids, title_embeddings, book_titles):\n",
        "    # Prepare user-specific input\n",
        "    user_genre_features = user_genres.reshape(1, -1)\n",
        "    user_author_id = author_encoder.transform([user_authors])[0]\n",
        "    user_author_id = np.array([user_author_id])\n",
        "    user_title_embedding = title_embeddings[0]  # Example user title embedding\n",
        "\n",
        "    user_input = [user_genre_features, user_author_id, user_title_embedding]\n",
        "\n",
        "    # Predict book recommendations\n",
        "    recommendations = model.predict(user_input)\n",
        "\n",
        "    # Sort and select top recommendations\n",
        "    top_recommendations_indices = recommendations.argsort()[-5:][::-1]  # Adjust the number of recommendations as needed\n",
        "    top_recommendations = [book_titles[i] for i in top_recommendations_indices]\n",
        "\n",
        "    return top_recommendations\n",
        "\n",
        "# Main program\n",
        "if __name__ == \"__main__\":\n",
        "    # Load and preprocess data\n",
        "    data = load_data_from_database()\n",
        "    genre_features, author_ids, title_embeddings = preprocess_data(data)\n",
        "    book_titles = [title for _, title, _ in data]\n",
        "\n",
        "    # Prompt the user to select genres and authors of interest\n",
        "    selected_genres = input(\"Enter genres of interest (comma-separated): \").split(',')\n",
        "    selected_authors = input(\"Enter authors of interest (comma-separated): \").split(',')\n",
        "\n",
        "    # Filter data based on user selections\n",
        "    selected_data = [item for item in data if any(genre in item[2] for genre in selected_genres)\n",
        "                     and any(author in item[0] for author in selected_authors)]\n",
        "\n",
        "    # Create and train the recommendation model\n",
        "    num_genres = genre_features.shape[1]\n",
        "    num_authors = len(set(author_ids))\n",
        "    num_titles = title_embeddings.shape[0]\n",
        "\n",
        "    model = create_recommendation_model(num_genres, num_authors, num_titles)\n",
        "    train_recommendation_model(model, genre_features, author_ids, title_embeddings)\n",
        "\n",
        "    # Example: Generate book recommendations based on user preferences\n",
        "    if selected_data:\n",
        "        user_genres = set(selected_genres)\n",
        "        user_authors = set(selected_authors)\n",
        "        recommendations = generate_recommendations(model, user_genres, user_authors, genre_features, author_ids, title_embeddings, book_titles)\n",
        "\n",
        "        print(\"Top Book Recommendations:\")\n",
        "        for i, book in enumerate(recommendations):\n",
        "            print(f\"{i+1}. {book}\")\n",
        "    else:\n",
        "        print(\"No books match the selected genres and authors.\")\n"
      ],
      "metadata": {
        "id": "HO2nzmPy11em"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import random\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Connect to the SQLite database\n",
        "conn = sqlite3.connect('books.db')\n",
        "c = conn.cursor()\n",
        "\n",
        "# Get all books from the database\n",
        "c.execute(\"SELECT * FROM books\")\n",
        "rows = c.fetchall()\n",
        "\n",
        "# Assume we have some function to get user ratings.\n",
        "def get_user_rating(book):\n",
        "    print(f\"Please rate the book '{book[1]}' by {book[2]} (1-5): \")\n",
        "    return int(input())  # Convert user rating to integer.\n",
        "\n",
        "# Randomly select 5 books for the user to rate.\n",
        "random_books = random.sample(rows, 5)\n",
        "user_ratings = [get_user_rating(book) for book in random_books]\n",
        "\n",
        "# Prepare data for training the model.\n",
        "X_train = [[book[2], book[3]] for book in rows]  # author and genre as features.\n",
        "y_train = [rating for rating in user_ratings]\n",
        "\n",
        "# Encoding categorical data (author & genre)\n",
        "label_encoder_author = LabelEncoder()\n",
        "X_train_encoded_author = label_encoder_author.fit_transform([x[0] for x in X_train])\n",
        "\n",
        "label_encoder_genre = LabelEncoder()\n",
        "X_train_encoded_genre= label_encoder_genre.fit_transform([x[1] for x in X_train])\n",
        "\n",
        "column_transformer = ColumnTransformer(\n",
        "    [('encoder', OneHotEncoder(), [0, 1])],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "X_train_encoded_full= column_transformer.fit_transform(np.column_stack((X_train_encoded_author,X_train_encoded_genre)))\n",
        "\n",
        "# Convert sparse matrix to dense\n",
        "X_train_encoded_full=X_train_encoded_full.toarray()\n",
        "\n",
        "# Define Keras model\n",
        "model=Sequential()\n",
        "model.add(Dense(10,input_dim=X_train_encoded_full.shape[1],activation='relu'))\n",
        "model.add(Dense(10,activation='relu'))\n",
        "model.add(Dense(1,activation='linear'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='mean_squared_error',optimizer='adam')\n",
        "\n",
        "# Fit model with our training data.\n",
        "model.fit(X_train_encoded_full,y_train,epochs=100,batch_size=10)\n",
        "\n",
        "def recommend_book(user_rating):\n",
        "    X_test_author_labelencoded=label_encoder_author.transform([user_rating[0]])\n",
        "    X_test_genre_labelencoded=label_encoder_genre.transform([user_rating[1]])\n",
        "\n",
        "    X_test_onehotencoded=column_transformer.transform(np.column_stack((X_test_author_labelencoded,X_test_genre_labelencoded)))\n",
        "\n",
        "    # Convert sparse matrix to dense\n",
        "    X_test_onehotencoded=X_test_onehotencoded.toarray()\n",
        "\n",
        "    prediction=model.predict(X_test_onehotencoded)\n",
        "\n",
        "    recommended_book_index=np.argmax(prediction)\n",
        "\n",
        "    return rows[recommended_book_index]\n",
        "\n",
        "print(\"Recommended Book: \", recommend_book(user_ratings))\n"
      ],
      "metadata": {
        "id": "35iAnPKg13_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "# Connect to the SQLite database\n",
        "conn = sqlite3.connect('books.db')\n",
        "\n",
        "# Read data from database into a pandas DataFrame\n",
        "df = pd.read_sql_query(\"SELECT * FROM books\", conn)\n",
        "\n",
        "# Replace missing authors with 'Unknown Author'\n",
        "df['authors'] = df['authors'].replace({None: 'Unknown Author'})\n",
        "\n",
        "# Split multiple authors into lists\n",
        "df['authors'] = df['authors'].str.split(',')\n",
        "\n",
        "# Convert genre to lowercase and replace 'unknown genre' with 'unknown_genre'\n",
        "df['genres'] = df['genres'].str.lower().replace({'unknown genre': 'unknown_genre'})\n",
        "\n",
        "# Initialize MultiLabelBinarizer for author column\n",
        "mlb_authors = MultiLabelBinarizer()\n",
        "authors_encoded = mlb_authors.fit_transform(df.pop('authors'))\n",
        "\n",
        "# Convert author-encoded array into DataFrame and concatenate with original DataFrame\n",
        "df_authors_encoded = pd.DataFrame(authors_encoded, columns=mlb_authors.classes_)\n",
        "df_processed = pd.concat([df, df_authors_encoded], axis=1)\n",
        "\n",
        "print(df_processed.head())\n",
        "\n"
      ],
      "metadata": {
        "id": "-5o48FWy16Jg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder, OneHotEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Connect to the SQLite database\n",
        "conn = sqlite3.connect('books.db')\n",
        "\n",
        "# Read data from database into a pandas DataFrame\n",
        "df = pd.read_sql_query(\"SELECT * FROM books\", conn)\n",
        "\n",
        "# Replace missing authors with 'Unknown Author'\n",
        "df['authors'] = df['authors'].replace({None: 'Unknown Author'})\n",
        "\n",
        "# Split multiple authors into lists\n",
        "df['authors'] = df['authors'].str.split(',')\n",
        "\n",
        "# Convert genre to lowercase and replace 'unknown genre' with 'unknown_genre'\n",
        "df['genres'] = df['genres'].str.lower().replace({'unknown genre': 'unknown_genre'})\n",
        "\n",
        "# Initialize MultiLabelBinarizer for author column\n",
        "mlb_authors = MultiLabelBinarizer()\n",
        "authors_encoded = mlb_authors.fit_transform(df.pop('authors'))\n",
        "\n",
        "# Convert author-encoded array into DataFrame and concatenate with original DataFrame\n",
        "df_authors_encoded = pd.DataFrame(authors_encoded, columns=mlb_authors.classes_)\n",
        "df_processed_author = pd.concat([df, df_authors_encoded], axis=1)\n",
        "\n",
        "le_genres= LabelEncoder()\n",
        "genres_encoded= le_genres.fit_transform(df_processed_author.pop('genres'))\n",
        "\n",
        "one_hot_encoder_genres= OneHotEncoder(sparse=False)\n",
        "genres_onehotencoded= one_hot_encoder_genres.fit_transform(genres_encoded.reshape(-1,1))\n",
        "\n",
        "df_genres_onehotencoded=pd.DataFrame(genres_onehotencoded,\n",
        "                                     columns=[f\"genre_{genre}\" for genre in le_genres.classes_])\n",
        "\n",
        "df_processed=pd.concat([df_processed_author.reset_index(drop=True),\n",
        "                        df_genres_onehotencoded.reset_index(drop=True)],axis=1)\n",
        "\n",
        "\n",
        "def get_user_rating(book):\n",
        "    print(f\"Please rate the book '{book[1]}' (1-5): \")\n",
        "    return float(input())  # Convert user rating to float.\n",
        "\n",
        "random_books_indices=np.random.choice(df_processed.shape[0], size=5)\n",
        "random_books_ratings=[get_user_rating(df.iloc[i]) for i in random_books_indices]\n",
        "\n",
        "X_train=df_processed.drop(columns=['title', 'unique_id']).values[random_books_indices].astype(float)\n",
        "y_train=np.array(random_books_ratings).astype(float)\n",
        "\n",
        "model=Sequential()\n",
        "model.add(Dense(10,input_dim=X_train.shape[1],activation='relu'))\n",
        "model.add(Dense(10,activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(loss='mean_squared_error',optimizer='adam')\n",
        "\n",
        "model.fit(X_train,y_train,epochs=100,batch_size=10)\n",
        "\n",
        "# Save the trained model\n",
        "from tensorflow.keras.models import save_model\n",
        "save_model(model, 'my_trained_model.h5')\n",
        "\n",
        "X_test=df_processed.drop(columns=['title', 'unique_id']).values.astype(float)\n",
        "\n",
        "predictions=model.predict(X_test)\n",
        "recommended_book_index=np.argmax(predictions)\n",
        "\n",
        "print(\"Recommended Book: \", df.iloc[recommended_book_index]['title'])"
      ],
      "metadata": {
        "id": "y1aN9TuN18Wc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the trained model from a file\n",
        "model = load_model('my_trained_model.h5')\n",
        "\n",
        "X_test=df_processed.drop(columns=['title', 'unique_id']).values.astype(float)\n",
        "predictions=model.predict(X_test)\n",
        "recommended_book_index=np.argmax(predictions)\n",
        "\n",
        "print(\"Recommended Book: \", df.iloc[recommended_book_index]['title'])"
      ],
      "metadata": {
        "id": "C5NHqGNu1-In"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to the SQLite database\n",
        "conn = sqlite3.connect('my_database.db')\n",
        "\n",
        "# Create cursor object\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Create table - RATINGS\n",
        "cursor.execute('''CREATE TABLE ratings\n",
        "             ([generated_id] INTEGER PRIMARY KEY,[username] text, [unique_id] integer, [rating] float)''')\n",
        "\n",
        "conn.commit()\n"
      ],
      "metadata": {
        "id": "AORt1xUw2CN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tensorflow.keras.models import load_model, save_model\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "def get_user_rating(book):\n",
        "    print(f\"Please rate the book '{book[1]}' (1-5): \")\n",
        "    return float(input())  # Convert user rating to float.\n",
        "\n",
        "def train_model(X_train, y_train, model_path):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(10,input_dim=X_train.shape[1],activation='relu'))\n",
        "    model.add(Dense(10,activation='relu'))\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    model.compile(loss='mean_squared_error',optimizer='adam')\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train,y_train,epochs=100,batch_size=10)\n",
        "\n",
        "    # Save the trained model\n",
        "    save_model(model, model_path)\n",
        "\n",
        "# Connect to the SQLite database\n",
        "conn = sqlite3.connect('my_database.db')\n",
        "\n",
        "# Ask user for username\n",
        "username = input(\"Enter your username: \")\n",
        "\n",
        "# Check if user exists in ratings table:\n",
        "user_exists = pd.read_sql_query(f\"SELECT * FROM ratings WHERE username='{username}'\", conn).shape[0] > 0\n",
        "\n",
        "if not user_exists:\n",
        "   print(\"New User! Please rate some books.\")\n",
        "else:\n",
        "   print(\"Welcome back! Loading your personalized recommendations...\")\n",
        "\n",
        "model_path = f'models/{username}_model.h5'\n",
        "\n",
        "if os.path.exists(model_path):\n",
        "     # Load existing recommendation engine from file\n",
        "     loaded_model = load_model(model_path)\n",
        "else:\n",
        "     print(\"It seems like you haven't rated any books yet.\")\n",
        "     print(\"Let's start by rating some books!\")\n",
        "\n",
        "random_books_indices=np.random.choice(df_processed.shape[0], size=5)\n",
        "random_books_ratings=[]\n",
        "for i in random_books_indices:\n",
        "      unique_id=df.iloc[i]['unique_id']\n",
        "      already_rated=pd.read_sql_query(f\"SELECT * FROM ratings WHERE username='{username}' AND unique_id='{unique_id}'\",conn).shape[0]>0\n",
        "\n",
        "\n",
        "      if not already_rated:\n",
        "          random_books_ratings.append((unique_id,get_user_rating(df.iloc[i])))\n",
        "\n",
        "X_train=df_processed.drop(columns=['title', 'unique_id']).values[random_books_indices].astype(float)\n",
        "y_train=np.array([rating for _,rating in random_books_ratings]).astype(float)\n",
        "\n",
        "cursor=conn.cursor()\n",
        "for unique_id,rating in random_books_ratings:\n",
        "\n",
        "        cursor.execute(f\"INSERT INTO ratings (username, unique_id,rating) VALUES ('{username}', '{unique_id}', {rating})\")\n",
        "        conn.commit()\n",
        "\n",
        "train_model(X_train,y_train,model_path)"
      ],
      "metadata": {
        "id": "QaG7zH5K2EJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sqlite3\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model, save_model\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder, OneHotEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "#read from database containing the books\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "# Connect to the SQLite database\n",
        "conn = sqlite3.connect('books.db')\n",
        "\n",
        "# Read data from database into a pandas DataFrame\n",
        "df = pd.read_sql_query(\"SELECT * FROM books\", conn)\n",
        "\n",
        "# Replace missing authors with 'Unknown Author'\n",
        "df['authors'] = df['authors'].replace({None: 'Unknown Author'})\n",
        "\n",
        "# Split multiple authors into lists\n",
        "df['authors'] = df['authors'].str.split(',')\n",
        "\n",
        "# Convert genre to lowercase and replace 'unknown genre' with 'unknown_genre'\n",
        "df['genres'] = df['genres'].str.lower().replace({'unknown genre': 'unknown_genre'})\n",
        "\n",
        "# Initialize MultiLabelBinarizer for author column\n",
        "mlb_authors = MultiLabelBinarizer()\n",
        "authors_encoded = mlb_authors.fit_transform(df.pop('authors'))\n",
        "\n",
        "# Convert author-encoded array into DataFrame and concatenate with original DataFrame\n",
        "df_authors_encoded = pd.DataFrame(authors_encoded, columns=mlb_authors.classes_)\n",
        "df_processed = pd.concat([df, df_authors_encoded], axis=1)\n",
        "\n",
        "df_processed=pd.concat([df_processed_author.reset_index(drop=True), df_genres_onehotencoded.reset_index(drop=True)],axis=1)\n",
        "\n",
        "def get_user_rating(book):\n",
        "    print(f\"Please rate the book '{book[1]}' (1-5): \")\n",
        "    return float(input())  # Convert user rating to float.\n",
        "\n",
        "def train_model(X_train, y_train, model_path):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(10,input_dim=X_train.shape[1],activation='relu'))\n",
        "    model.add(Dense(10,activation='relu'))\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    model.compile(loss='mean_squared_error',optimizer='adam')\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train,y_train,epochs=100,batch_size=10)\n",
        "\n",
        "    # Save the trained model\n",
        "    save_model(model, model_path)\n",
        "\n",
        "def recommend_book(model):\n",
        "   # For simplicity we will just predict rating for every book in our database and return one with highest predicted rating.\n",
        "   X_all_books = df_processed.drop(columns=['title', 'unique_id']).values.astype(float)\n",
        "   predictions = loaded_model.predict(X_all_books)\n",
        "\n",
        "   recommended_book_index = np.argmax(predictions)\n",
        "\n",
        "   recommended_book_title = df.iloc[recommended_book_index]['title']\n",
        "\n",
        "   print(f\"We recommend you to read: {recommended_book_title}\")\n",
        "\n",
        "# Connect to the SQLite database\n",
        "conn = sqlite3.connect('my_database.db')\n",
        "\n",
        "# Ask user for username\n",
        "username = input(\"Enter your username: \")\n",
        "\n",
        "model_path = f'models/{username}_model.h5'\n",
        "\n",
        "if os.path.exists(model_path):\n",
        "    # Load existing recommendation engine from file\n",
        "    loaded_model = load_model(model_path)\n",
        "\n",
        "    retrain_choice=input(\"Do you want to retrain your recommendation engine? (yes/no): \")\n",
        "\n",
        "    if retrain_choice.lower()=='yes':\n",
        "        print(\"Let's rate some books!\")\n",
        "        user_ratings=pd.read_sql_query(f\"SELECT * FROM ratings WHERE username='{username}'\",conn)\n",
        "\n",
        "        if not user_ratings.empty:\n",
        "            X_train=df_processed[df_processed['unique_id'].isin(user_ratings['unique_id'])].drop(columns=['title', 'unique_id']).values.astype(float)\n",
        "            y_train=user_ratings['rating'].values.astype(float)\n",
        "\n",
        "            train_model(X_train,y_train,model_path)\n",
        "\n",
        "else:\n",
        "    # Prompt new users to train a model\n",
        "    print(\"Welcome, new user! Let's rate some books and create your personalized recommendation engine.\")\n",
        "\n",
        "    random_books_indices=np.random.choice(df_processed.shape[0], size=5)\n",
        "\n",
        "    for i in random_books_indices:\n",
        "        unique_id=df.iloc[i]['unique_id']\n",
        "        already_rated=pd.read_sql_query(f\"SELECT * FROM ratings WHERE username='{username}' AND unique_id='{unique_id}'\",conn).shape[0]>0\n",
        "\n",
        "        if not already_rated:\n",
        "            rating=get_user_rating(df.iloc[i])\n",
        "            if rating==0.0:\n",
        "               continue\n",
        "\n",
        "            cursor=conn.cursor()\n",
        "            cursor.execute(f\"INSERT INTO ratings (username, unique_id,rating) VALUES ('{username}', '{unique_id}', {rating})\")\n",
        "            conn.commit()\n",
        "\n",
        "    # After collecting ratings, train the model\n",
        "    user_ratings=pd.read_sql_query(f\"SELECT * FROM ratings WHERE username='{username}'\",conn)\n",
        "\n",
        "    X_train=df_processed[df_processed['unique_id'].isin(user_ratings['unique_id'])].drop(columns=['title', 'unique_id']).values.astype(float)\n",
        "    y_train=user_ratings['rating'].values.astype(float)\n",
        "\n",
        "    train_model(X_train,y_train,model_path)\n",
        "\n",
        "rate_books_choice=input(\"Do you want to rate some books? (yes/no): \")\n",
        "\n",
        "if rate_books_choice.lower()=='yes':\n",
        "      random_books_indices=np.random.choice(df_processed.shape[0], size=5)\n",
        "\n",
        "      for i in random_books_indices:\n",
        "          unique_id=df.iloc[i]['unique_id']\n",
        "          already_rated=pd.read_sql_query(f\"SELECT * FROM ratings WHERE username='{username}' AND unique_id='{unique_id}'\",conn).shape[0]>0\n",
        "\n",
        "          if not already_rated:\n",
        "              rating=get_user_rating(df.iloc[i])\n",
        "              if rating==0.0:\n",
        "                 continue\n",
        "\n",
        "              cursor=conn.cursor()\n",
        "              cursor.execute(f\"INSERT INTO ratings (username, unique_id,rating) VALUES ('{username}', '{unique_id}', {rating})\")\n",
        "              conn.commit()\n",
        "\n",
        "recommend_book(loaded_model)\n"
      ],
      "metadata": {
        "id": "QXImRcvC2GSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ask user for username\n",
        "username = input(\"Enter your username: \")\n",
        "\n",
        "model_path = f'models/{username}_model.h5'\n",
        "\n",
        "if os.path.exists(model_path):\n",
        "    # Load existing recommendation engine from file\n",
        "    loaded_model = load_model(model_path)\n",
        "\n",
        "    retrain_choice=input(\"Do you want to retrain your recommendation engine? (yes/no): \")\n",
        "\n",
        "    if retrain_choice.lower()=='yes':\n",
        "        print(\"Let's rate some books!\")\n",
        "        user_ratings=pd.read_sql_query(f\"SELECT * FROM ratings WHERE username='{username}'\",conn)\n",
        "\n",
        "        if not user_ratings.empty:\n",
        "            X_train=df_processed[df_processed['unique_id'].isin(user_ratings['unique_id'])].drop(columns=['title', 'unique_id']).values.astype(float)\n",
        "            y_train=user_ratings['rating'].values.astype(float)\n",
        "\n",
        "            train_model(X_train,y_train,model_path)\n",
        "\n",
        "else:\n",
        "    # Prompt new users to train a model\n",
        "    print(\"Welcome, new user! Let's rate some books and create your personalized recommendation engine.\")\n",
        "\n",
        "    # Code for gathering ratings and training a new model goes here.\n"
      ],
      "metadata": {
        "id": "hAWWJ7Tx2IyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tkinter as tk\n",
        "from tkinter import messagebox\n",
        "from tkinter import simpledialog\n",
        "import os\n",
        "import sqlite3\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential, load_model, save_model\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "#read from database containing the books\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "# Connect to the SQLite database\n",
        "conn = sqlite3.connect('books.db')\n",
        "\n",
        "# Read data from database into a pandas DataFrame\n",
        "df = pd.read_sql_query(\"SELECT * FROM books\", conn)\n",
        "\n",
        "# Replace missing authors with 'Unknown Author'\n",
        "df['authors'] = df['authors'].replace({None: 'Unknown Author'})\n",
        "\n",
        "# Split multiple authors into lists\n",
        "df['authors'] = df['authors'].str.split(',')\n",
        "\n",
        "# Convert genre to lowercase and replace 'unknown genre' with 'unknown_genre'\n",
        "df['genres'] = df['genres'].str.lower().replace({'unknown genre': 'unknown_genre'})\n",
        "\n",
        "class BookRecommender:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.conn = sqlite3.connect('my_database.db')\n",
        "        self.username = None\n",
        "        self.model = None\n",
        "\n",
        "    def load_model(self):\n",
        "        model_path = f'models/{self.username}_model.h5'\n",
        "        if os.path.exists(model_path):\n",
        "            self.model = load_model(model_path)\n",
        "        else:\n",
        "            messagebox.showerror(\"Error\", \"No model found for this user.\")\n",
        "\n",
        "    def get_user_rating(self, book):\n",
        "        rating = simpledialog.askfloat(\"Input\", f\"Rate the book '{book[1]}' (1-5):\", minvalue=1, maxvalue=5)\n",
        "        return rating  # Convert user rating to float.\n",
        "\n",
        "    def rate_books(self):\n",
        "        random_books_indices = np.random.choice(df_processed.shape[0], size=5)\n",
        "        for i in random_books_indices:\n",
        "            book = df.iloc[i]\n",
        "            rating = self.get_user_rating(book)\n",
        "            if rating:\n",
        "                # Save the rating in the database\n",
        "                cursor = self.conn.cursor()\n",
        "                cursor.execute(f\"INSERT INTO ratings (username, unique_id, rating) VALUES ('{self.username}', '{book[0]}', {rating})\")\n",
        "                self.conn.commit()\n",
        "\n",
        "    def train_new_model(self):\n",
        "        print(\"Welcome, new user! Let's rate some books and create your personalized recommendation engine.\")\n",
        "        self.rate_books()\n",
        "\n",
        "        user_ratings = pd.read_sql_query(f\"SELECT * FROM ratings WHERE username='{self.username}'\", self.conn)\n",
        "\n",
        "        X_train = df_processed[df_processed['unique_id'].isin(user_ratings['unique_id'])].drop(columns=['title', 'unique_id']).values.astype(float)\n",
        "        y_train = user_ratings['rating'].values.astype(float)\n",
        "\n",
        "        self.train_model(X_train, y_train)\n",
        "\n",
        "    def rate_and_train(self):\n",
        "        self.rate_books()\n",
        "        user_ratings = pd.read_sql_query(f\"SELECT * FROM ratings WHERE username='{self.username}'\", self.conn)\n",
        "\n",
        "        X_train = df_processed[df_processed['unique_id'].isin(user_ratings['unique_id'])].drop(columns=['title', 'unique_id']).values.astype(float)\n",
        "        y_train = user_ratings['rating'].values.astype(float)\n",
        "\n",
        "        self.train_model(X_train, y_train)\n",
        "\n",
        "    def recommend_book(self):\n",
        "        if self.model is None:\n",
        "            messagebox.showerror(\"Error\", \"No model found for this user.\")\n",
        "            return\n",
        "   # For simplicity we will just predict rating for every book in our database and return one with highest predicted rating.\n",
        "        X_all_books = df_processed.drop(columns=['title', 'unique_id']).values.astype(float)\n",
        "        predictions = self.model.predict(X_all_books)\n",
        "\n",
        "        recommended_book_index = np.argmax(predictions)\n",
        "\n",
        "        recommended_book_title = df.iloc[recommended_book_index]['title']\n",
        "\n",
        "        messagebox.showinfo(\"Recommendation\", f\"We recommend you to read: {recommended_book_title}\")\n",
        "class App:\n",
        "\n",
        "    def __init__(self, root, recommender):\n",
        "        self.recommender = recommender\n",
        "\n",
        "        self.username_label = tk.Label(root, text=\"Enter your username:\")\n",
        "        self.username_label.pack()\n",
        "        self.username_entry = tk.Entry(root)\n",
        "        self.username_entry.pack()\n",
        "\n",
        "        self.load_model_button = tk.Button(root, text=\"Load Model\", command=self.load_model)\n",
        "        self.load_model_button.pack()\n",
        "\n",
        "        self.recommend_button = tk.Button(root, text=\"Get Recommendation\", command=self.recommend_book)\n",
        "        self.recommend_button.pack()\n",
        "\n",
        "        self.rate_book_button = tk.Button(root, text=\"Rate a Random Book\", command=self.rate_random_book)\n",
        "        self.rate_book_button.pack()\n",
        "\n",
        "    def load_model(self):\n",
        "        username = self.username_entry.get()\n",
        "        if not username:\n",
        "            messagebox.showerror(\"Error\", \"You must enter a username.\")\n",
        "            return\n",
        "        self.recommender.username = username\n",
        "        self.recommender.load_model()\n",
        "\n",
        "    def recommend_book(self):\n",
        "        self.recommender.recommend_book()\n",
        "\n",
        "    def rate_random_book(self):\n",
        "        random_book_index = np.random.choice(df_processed.shape[0], size=1)[0]\n",
        "        book = df.iloc[random_book_index]\n",
        "        rating = self.recommender.get_user_rating(book)\n",
        "        if rating:\n",
        "            # Save the rating in the database\n",
        "            cursor = self.recommender.conn.cursor()\n",
        "            cursor.execute(f\"INSERT INTO ratings (username, unique_id, rating) VALUES ('{self.recommender.username}', '{book['unique_id']}', {rating})\")\n",
        "            self.recommender.conn.commit()\n",
        "\n",
        "            # Regenerate the model with the new rating\n",
        "            self.recommender.rate_and_train()\n",
        "\n",
        "root = tk.Tk()\n",
        "recommender = BookRecommender()\n",
        "app = App(root, recommender)\n",
        "root.mainloop()\n"
      ],
      "metadata": {
        "id": "0uuMSR0f2K-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cB89K8tf2ORC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}